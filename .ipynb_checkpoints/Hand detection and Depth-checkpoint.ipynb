{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] start streaming...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyrealsense2.frameset Z16 RGB8 MOTION_XYZ32F MOTION_XYZ32F #8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "W = 848\n",
    "H = 480\n",
    "fps = 30\n",
    "\n",
    "from yolo import YOLO\n",
    "obj_labels = open(\"models/yolov3-coco/coco-labels\").read().strip().split('\\n')\n",
    "#yolo = YOLO(\"models/cross-hands.cfg\", \"models/cross-hands.weights\", [\"hand\"])\n",
    "yolo = YOLO(\"models/cross-hands-tiny.cfg\", \"models/cross-hands-tiny.weights\", [\"hand\"])\n",
    "yolo.size = int(416)\n",
    "yolo.confidence = float(0.2)\n",
    "obj_model= YOLO(\"models/yolov3-coco/yolov3.cfg\", \"models/yolov3-coco/yolov3.weights\", obj_labels)\n",
    "obj_model.size = int(416)\n",
    "obj_model.confidence = float(0.6)\n",
    "\n",
    "rs_serial='031222070617' #serial number for realsense camera\n",
    "#rs_serial ='908212071265'\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "#config.enable_stream(rs.stream.depth, W, H, rs.format.z16, fps)\n",
    "#config.enable_stream(rs.stream.color, W, H, rs.format.rgb8, fps)\n",
    "config.enable_device(rs_serial)\n",
    "#config.enable_device()\n",
    "\n",
    "\n",
    "dec_filter = rs.decimation_filter()  # Decimation-reduce df density\n",
    "spat_filter = rs.spatial_filter()    # Spatial-spatial smoothing\n",
    "temp_filter = rs.temporal_filter()   # Temporal-reduces temporal noise\n",
    "\n",
    "print(\"[INFO] start streaming...\")\n",
    "#profile = pipeline.start(config)\n",
    "profile = pipeline.start(config)\n",
    "pipeline.wait_for_frames()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'len'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-72f82a4429dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcurrentSelect\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"<\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                     \u001b[0mpin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcurrentSelect\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\">\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                     \u001b[0mpin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'len'"
     ]
    }
   ],
   "source": [
    "\n",
    "#device = profile.get_device()\n",
    "#depth_sensor = device.first_depth_sensor()\n",
    "#device.hardware_reset()\n",
    "\n",
    "#points = point_cloud.calculate(depth_frame)\n",
    "#color_frame = frameset_before.get_color_frame()\n",
    "    \n",
    "#verts = np.asanyarray(points.get_vertices()).view(np.float32).reshape(-1, W, 3)  # xyz\n",
    "# Convert images to numpy arrays\n",
    "\n",
    "    \n",
    "\n",
    "depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "align = rs.align(rs.stream.color)\n",
    "point_cloud = rs.pointcloud()\n",
    "hands = 1\n",
    "\n",
    "def getIntelFrames():\n",
    "    \n",
    "    frames = pipeline.wait_for_frames()\n",
    "    #frames = dec_filter.process(frames).as_frameset()\n",
    "    #frames = spat_filter.process(frames).as_frameset()\n",
    "    #frames = temp_filter.process(frames).as_frameset()\n",
    "    aligned_frames = align.process(frames)  \n",
    "    depth_frame = aligned_frames.get_depth_frame()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    depth = np.asanyarray(depth_frame.get_data())\n",
    "    \n",
    "    return color_image,depth\n",
    "\n",
    "    \n",
    "\n",
    "def showColorizedDepth(depth_frame, detection,distanceString):\n",
    "    id, name, confidence, x, y, w, h = detected_instance\n",
    "    color = (0, 255, 255)\n",
    "   \n",
    "    xmin_depth = x+round(w/4)\n",
    "    ymin_depth = y+round(h/4)\n",
    "    xmax_depth = x+round(w*.75)\n",
    "    ymax_depth = y+round(h*.75) \n",
    "    \n",
    "    colorizer = rs.colorizer()\n",
    "    colorized_depth = np.asanyarray(colorizer.colorize(depth_frame).get_data())\n",
    "    cv2.rectangle(colorized_depth, (xmin_depth, ymin_depth), \n",
    "                 (xmax_depth, ymax_depth), (255, 255, 255), 2)\n",
    "\n",
    "    cv2.putText(colorized_depth, distanceString, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5, color, 2)\n",
    "    cv2.imshow(\"Depth Frame\",colorized_depth)\n",
    "\n",
    "        \n",
    "cell_phone_flag= False\n",
    "set_interaction=False\n",
    "\n",
    "\n",
    "def cellPhoneDetection(frame, depth):\n",
    "    width_obj, height_obj, inference_time_obj, results_obj = obj_model.inference(frame)\n",
    "    for detection in results_obj:\n",
    "        id, name, confidence, x, y, w, h = detection\n",
    "        #print(detection, name)\n",
    "        if(name=='cell phone'):\n",
    "            cx = x + (w / 2)\n",
    "            cy = y + (h / 2)\n",
    "            xmin_depth = x+round(w/4)\n",
    "            ymin_depth = y+round(h/4)\n",
    "            xmax_depth = x+round(w*.75)\n",
    "            ymax_depth = y+round(h*.75)\n",
    "            depth_phone = depth[ymin_depth:ymax_depth,xmin_depth:xmax_depth].astype(float)\n",
    "            depth_phone_scaled = depth_phone * depth_scale\n",
    "            dist,_,_,_ = cv2.mean(depth_phone_scaled)\n",
    "            #print(\"Detected {0:.3} meters away.\".format(dist))\n",
    "            distanceString = \"Detected {0:.3} meters away.\".format(dist)\n",
    "            #postCoords(dist)\n",
    "                                 \n",
    "        \n",
    "            return True, detection, dist,inference_time_obj\n",
    "            \n",
    "    return False,False,0,inference_time_obj\n",
    "\n",
    "\n",
    "\n",
    "pin = \"\"\n",
    "\n",
    "counter = 0\n",
    "currentSelect = \"\"\n",
    "\n",
    "while True:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    color_image,depth = getIntelFrames()\n",
    "     \n",
    "\n",
    "    frame = color_image\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    \n",
    "    # Get data scale from the device and convert to meters\n",
    "    \n",
    "    \n",
    "    width, height, inference_time, results = yolo.inference(frame)\n",
    "    hp_startTime = time.time()\n",
    "    frame,indexX,indexY = getFingers(frame)\n",
    "    hp_endTime = time.time()\n",
    "    \n",
    " #   phone_detected, cellObj, cellDist,inference_time_obj = cellPhoneDetection(frame, depth)#continuous cellphone detection\n",
    " #   if(phone_detected):\n",
    " #       color=(0,255,0)\n",
    " #       inference_time=inference_time_obj+inference_time\n",
    "\n",
    "        \n",
    " #       distanceString = \"Detected {0:.3} meters away.\".format(cellDist)\n",
    " #       cv2.putText(frame, \"phone \"+distanceString, (15, 95), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        \n",
    "            \n",
    "    \n",
    "    if(cell_phone_flag):\n",
    "        #if(distHand):\n",
    "        #    postCoords(distHand,interactDist)\n",
    "        \n",
    "        if(True):\n",
    "            id, name, confidence, x, y, w, h = interActionZone\n",
    "\n",
    "            h= h+100 #scaling grid larger\n",
    "            w=w+100\n",
    "\n",
    "            for i in range(0, 4):\n",
    "\n",
    "                rowy=i*h/3\n",
    "                \n",
    "                s1 = (int(x+w/3),int(y+rowy))\n",
    "                e1 = (int(x+w*2/3),int(y+h/3+rowy))\n",
    "                s2 = (int(x+w*2/3),int(y+rowy))\n",
    "                e2 = (int(x+w),int(y+h/3+rowy))\n",
    "                s3 = (int(x+w),int(y+rowy))\n",
    "                e3 = (int(x+w*4/3),int(y+h/3+rowy))\n",
    "\n",
    "                color = (255, 0, 0)\n",
    "                colorSelect = (0, 255, 0)\n",
    "\n",
    "                frame = cv2.rectangle(frame,s1 , e1, color, thickness)\n",
    "                frame = cv2.rectangle(frame,s2 , e2, color, thickness)\n",
    "                frame = cv2.rectangle(frame,s3 , e3, color, thickness)\n",
    "                \n",
    "                symbol = \"\"\n",
    "\n",
    "                if (i == 3):\n",
    "                    symbol = \"<\"\n",
    "                else:\n",
    "                    symbol = str(i * 3 + 1)\n",
    "                if (indexX >= int(x+w/3) and indexX <= int(x+w*2/3) and indexY >= int(y+rowy) and indexY <= int(y+h/3+rowy)):\n",
    "                    if (counter == 0 or currentSelect == symbol):\n",
    "                        counter = counter + 1\n",
    "                    else:\n",
    "                        counter = 0\n",
    "                    currentSelect = symbol\n",
    "                    frame = cv2.putText(frame, symbol, (int(x+w*1.5/3), int(y+h/6+rowy)), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       1, colorSelect, 2, cv2.LINE_AA)\n",
    "                else:\n",
    "                    frame = cv2.putText(frame, symbol, (int(x+w*1.5/3), int(y+h/6+rowy)), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       1, color, 2, cv2.LINE_AA)\n",
    "                if (i == 3):\n",
    "                    symbol = \"0\"\n",
    "                else:\n",
    "                    symbol = str(i * 3 + 2)\n",
    "                if (indexX >= int(x+w*2/3) and indexX <= int(x+w) and indexY >= int(y+rowy) and indexY <= int(y+h/3+rowy)):\n",
    "                    if (counter == 0 or currentSelect == symbol):\n",
    "                        counter = counter + 1\n",
    "                    else:\n",
    "                        counter = 0\n",
    "                    currentSelect = symbol\n",
    "                    frame = cv2.putText(frame, symbol, (int(x+w*2.5/3), int(y+h/6+rowy)), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       1, colorSelect, 2, cv2.LINE_AA)\n",
    "                else:\n",
    "                    frame = cv2.putText(frame, symbol, (int(x+w*2.5/3), int(y+h/6+rowy)), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       1, color, 2, cv2.LINE_AA)\n",
    "                if (i == 3):\n",
    "                    symbol = \">\"\n",
    "                else:\n",
    "                    symbol = str(i * 3 + 3)\n",
    "                if (indexX >= int(x+w) and indexX <= int(x+w*4/3) and indexY >= int(y+rowy) and indexY <= int(y+h/3+rowy)):\n",
    "                    if (counter == 0 or currentSelect == symbol):\n",
    "                        counter = counter + 1\n",
    "                    else:\n",
    "                        counter = 0\n",
    "                    currentSelect = symbol\n",
    "                    frame = cv2.putText(frame, symbol, (int(x+w*3.5/3), int(y+h/6+rowy)), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       1, colorSelect, 2, cv2.LINE_AA)\n",
    "                else:\n",
    "                    frame = cv2.putText(frame, symbol, (int(x+w*3.5/3), int(y+h/6+rowy)), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       1, color, 2, cv2.LINE_AA)\n",
    "\n",
    "            if (counter == 15):\n",
    "                if (currentSelect == \"<\"):\n",
    "                    pin = pin[0:len(pin)-1]\n",
    "                elif (currentSelect == \">\"):\n",
    "                    pin = \"\"\n",
    "                else:\n",
    "                    pin = pin + currentSelect\n",
    "\n",
    "            frame = cv2.putText(frame, pin, (int(x+w/3), int(y+h*3/2)), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, colorSelect, 2, cv2.LINE_AA)\n",
    "                \n",
    "            set_interaction =True\n",
    "        \n",
    "\n",
    "    else:\n",
    "        if(set_interaction==False):\n",
    "            #print(\"Interaction Zone Set\")\n",
    "            cell_phone_flag, interActionZone, cellDist,inference_time_obj = cellPhoneDetection(frame, depth)\n",
    "            interactDist = cellDist-.6\n",
    "            inference_time=inference_time_obj+inference_time\n",
    "\n",
    "\n",
    "    # sort by confidence\n",
    "    results.sort(key=lambda x: x[2])\n",
    "\n",
    "    # how many hands should be shown\n",
    "    hand_count = len(results)\n",
    "    if hands != -1:\n",
    "        hand_count = int(hands)               \n",
    "            \n",
    "   \n",
    "\n",
    "    # display hands\n",
    "    for detection in results[:hand_count]:\n",
    "        id, name, confidence, x, y, w, h = detection\n",
    "        cx = x + (w / 2)\n",
    "        cy = y + (h / 2)\n",
    "\n",
    "        # draw a bounding box rectangle and label on the image\n",
    "        color = (0, 255, 255)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "        xmin_depth = x+round(w/4)\n",
    "        ymin_depth = y+round(h/4)\n",
    "        xmax_depth = x+round(w*.75)\n",
    "        ymax_depth = y+round(h*.75)      \n",
    "        \n",
    "        \n",
    "        # Crop depth data:\n",
    "        depth_hand = depth[ymin_depth:ymax_depth,xmin_depth:xmax_depth].astype(float)\n",
    "        depth_hand_scaled = depth_hand * depth_scale\n",
    "        distHand,_,_,_ = cv2.mean(depth_hand_scaled)\n",
    "        distanceString = \"Detected {0:.3} meters away.\".format(distHand)\n",
    "        #showColorizedDepth(depth_frame,detection,distanceString)        \n",
    "       \n",
    "        # Display confidence and distance\n",
    "        text = \"%s (%s)\" % (name, round(confidence, 2))\n",
    "        cv2.putText(frame, text+distanceString, (15, 65), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, color, 2)\n",
    "\n",
    "    \n",
    "    if indexX:\n",
    "        indexDist=(depth[int(indexY),int(indexX)].astype(float))*depth_scale\n",
    "        iDistanceSTR = \"Detected {0:.3} meters away.\".format(indexDist)\n",
    "        cv2.putText(frame,\"Index Finger \"+ iDistanceSTR,(15,35),cv2.FONT_HERSHEY_SIMPLEX,0.5, (255, 0, 0), 2 )\n",
    "\n",
    "    \n",
    "    # display fps\n",
    "    cv2.putText(frame, f'H & C {round(1/(inference_time),2)} FPS', (frame.shape[1]-200,55), cv2.FONT_HERSHEY_SIMPLEX,0.5, (0,255,255), 2)\n",
    "    cv2.putText(frame,f'HP {round(1/(hp_endTime - hp_startTime),2)} FPS',(frame.shape[1]-200,35),cv2.FONT_HERSHEY_SIMPLEX,0.5, (0,255,255), 2 )\n",
    "\n",
    "    cv2.putText(frame,f'All {round(1/(time.time() - start_time),2)} FPS',(frame.shape[1]-200,15),cv2.FONT_HERSHEY_SIMPLEX,0.5, (0,255,255), 2 )\n",
    "        \n",
    "    cv2.imshow(\"preview\", frame)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "pipeline.stop()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#API_ENDPOINT ='http://localhost:8000/setCoords'\n",
    "API_ENDPOINT = 'https://t24blpcmsa.execute-api.us-east-1.amazonaws.com/dev'\n",
    "# fontScale\n",
    "fontScale = 1\n",
    "   \n",
    "# Blue color in BGR\n",
    "color = (255, 0, 0)\n",
    "  \n",
    "# Line thickness of 2 px\n",
    "thickness = 2\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "def getFingers(frame):\n",
    "    with mp_hands.Hands(min_detection_confidence=0.6, min_tracking_confidence=0.5) as hands:\n",
    "        \n",
    "\n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Flip on horizontal\n",
    "        #image = cv2.flip(image, 1)\n",
    "\n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detections\n",
    "        #print(results)\n",
    "        image_height, image_width, _ = image.shape\n",
    "\n",
    "\n",
    "        # Rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                xIndexFinger =hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width\n",
    "                yIndexFinger = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y* image_height\n",
    "                xMiddleFinger =hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].x * image_width\n",
    "                yMiddleFinger = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y* image_height\n",
    "                cv2.putText(image, 'o', (int(xIndexFinger)-10,int(yIndexFinger)-10), font, fontScale, (255, 0, 0), 4, cv2.LINE_AA)\n",
    "                #cv2.putText(image, 'o', (int(xMiddleFinger)-10,int(yMiddleFinger)-10), font, fontScale, (255, 255, 0), 4, cv2.LINE_AA)\n",
    "                return image, xIndexFinger, yIndexFinger\n",
    "        return image, False, False\n",
    "        \n",
    "        \n",
    "def postCoords(coords, interactionDist):\n",
    "    data = {\"currentDist\":coords,\"interactDist\":interactionDist}\n",
    "  \n",
    "    # sending post request and saving response as response object\n",
    "    requests.post(url = API_ENDPOINT +'/setCoords', data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "\n",
    "#rs_serial='030522070959' #serial number for realsense camera\n",
    "rs_serial ='031222070617'\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_device(rs_serial)\n",
    "#config.enable_stream(rs.stream.depth, W, H, rs.format.z16, 30)\n",
    "#config.enable_stream(rs.stream.color, W, H, rs.format.bgr8, 30)\n",
    "\n",
    "\n",
    "print(\"[INFO] start streaming...\")\n",
    "profile = pipeline.start(config)\n",
    "device = profile.get_device()\n",
    "depth_sensor = device.first_depth_sensor()\n",
    "device.hardware_reset()\n",
    "pipeline.wait_for_frames()\n",
    "pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/google/mediapipe/issues/2138\n",
    "#For me the error got away after I uninstalled and reinstalled the opencv-contrib-python for 4.5.2\n",
    "#MediaPipe doesn't require a specific opencv version: https://github.com/google/mediapipe/blob/master/requirements.txt#L4. Is it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_model.inference(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for detection in results_obj:\n",
    "    id, name, confidence, x, y, w, h = detection\n",
    "    #print(detection, name)\n",
    "    if(name=='cell phone'):\n",
    "        print(detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_point+40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
